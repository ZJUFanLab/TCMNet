{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T08:03:35.865954Z",
     "iopub.status.busy": "2025-06-05T08:03:35.865465Z",
     "iopub.status.idle": "2025-06-05T08:03:43.580937Z",
     "shell.execute_reply": "2025-06-05T08:03:43.580019Z",
     "shell.execute_reply.started": "2025-06-05T08:03:35.865913Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成分文件已生成：/slurm/home/yrd/liaolab/tanshuoyan/TCM-opt-Tan/PD/herb/GBL-herb/GBL-ingredient-fromBATMAN.csv\n",
      "靶点文件已生成：/slurm/home/yrd/liaolab/tanshuoyan/TCM-opt-Tan/PD/herb/GBL-herb/GBL-target-fromBATMAN.csv\n",
      "已更新 smiles 字段，文件：/slurm/home/yrd/liaolab/tanshuoyan/TCM-opt-Tan/PD/herb/GBL-herb/GBL-ingredient-fromBATMAN.csv\n"
     ]
    }
   ],
   "source": [
    "###step1\n",
    "###根据药材列表，从BATMAN数据库获取成分和靶点,\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# 防止 CSV 长字段溢出\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "####################################\n",
    "# 输入输出文件设置\n",
    "####################################\n",
    "DTD_input = \"/slurm/home/yrd/liaolab/tanshuoyan/TCM-opt-Tan/PD/herb/GBL-herb/GBL.txt\"\n",
    "ingredient_output = \"/slurm/home/yrd/liaolab/tanshuoyan/TCM-opt-Tan/PD/herb/GBL-herb/GBL-ingredient-fromBATMAN.csv\"\n",
    "target_output     = \"/slurm/home/yrd/liaolab/tanshuoyan/TCM-opt-Tan/PD/herb/GBL-herb/GBL-target-fromBATMAN.csv\"\n",
    "\n",
    "herb_browse_path                 = \"/slurm/home/yrd/liaolab/tanshuoyan/training_Data/TCM-database/BATMAN-TCM/download-data/herb_browse.txt\"\n",
    "known_file_path                  = \"/slurm/home/yrd/liaolab/tanshuoyan/training_Data/TCM-database/BATMAN-TCM/download-data/known_browse_by_ingredients.txt\"\n",
    "predicted_ing_file               = \"/slurm/home/yrd/liaolab/tanshuoyan/training_Data/TCM-database/BATMAN-TCM/download-data/predicted_browse_by_ingredinets.txt\"\n",
    "predicted_target_mapping_file    = \"/slurm/home/yrd/liaolab/tanshuoyan/training_Data/TCM-database/BATMAN-TCM/download-data/predicted_browse_by_targets.txt\"\n",
    "\n",
    "####################################\n",
    "# 第 1 部分：读取 herb 列表\n",
    "####################################\n",
    "herb_list = []\n",
    "with open(DTD_input, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        # 按制表符或逗号切分，取第 1 列\n",
    "        herb = re.split(r'[\\t,]\\s*', line)[0]\n",
    "        herb_list.append(herb)\n",
    "\n",
    "####################################\n",
    "# 第 2 部分：加载 herb_browse.txt\n",
    "####################################\n",
    "herb_data = {}\n",
    "with open(herb_browse_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    header = next(reader)\n",
    "    for row in reader:\n",
    "        if len(row) < 5:\n",
    "            continue\n",
    "        chinese_name   = row[1].strip()\n",
    "        ingredients_str = row[4].strip()\n",
    "        herb_data[chinese_name] = ingredients_str\n",
    "\n",
    "####################################\n",
    "# 第 3 部分：生成成分信息\n",
    "####################################\n",
    "output_rows = []\n",
    "for herb in herb_list:\n",
    "    if herb in herb_data:\n",
    "        ingredients_str = herb_data[herb]\n",
    "        if ingredients_str:\n",
    "            for ingredient in ingredients_str.split(\"|\"):\n",
    "                ingredient = ingredient.strip()\n",
    "                if \"(\" in ingredient and ingredient.endswith(\")\"):\n",
    "                    idx = ingredient.rfind(\"(\")\n",
    "                    name = ingredient[:idx].strip()\n",
    "                    cid  = ingredient[idx+1:-1].strip()\n",
    "                    output_rows.append([herb, name, cid])\n",
    "                else:\n",
    "                    output_rows.append([herb, ingredient, \"\"])\n",
    "        else:\n",
    "            output_rows.append([herb, \"\", \"\"])\n",
    "    else:\n",
    "        print(f\"Warning: 药材 {herb} 在 herb_browse.txt 中未找到。\")\n",
    "\n",
    "with open(ingredient_output, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"herbname\", \"ingredient_name\", \"PubChem_CID\"])\n",
    "    writer.writerows(output_rows)\n",
    "print(f\"成分文件已生成：{ingredient_output}\")\n",
    "\n",
    "####################################\n",
    "# 第 4 部分：生成靶点信息\n",
    "####################################\n",
    "# 已知\n",
    "known_targets = {}\n",
    "with open(known_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        if len(row) < 3: continue\n",
    "        cid = row[0].strip()\n",
    "        prots = [p.strip() for p in row[2].split(\"|\") if p.strip()]\n",
    "        known_targets[cid] = prots\n",
    "\n",
    "# 预测\n",
    "predicted_targets = {}\n",
    "with open(predicted_ing_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1:]:\n",
    "        parts = line.strip().split(maxsplit=2)\n",
    "        if len(parts) < 3: continue\n",
    "        cid = parts[0].strip()\n",
    "        preds = []\n",
    "        for tok in parts[2].split(\"|\"):\n",
    "            tok = tok.strip()\n",
    "            if \"(\" in tok and tok.endswith(\")\"):\n",
    "                idx = tok.rfind(\"(\")\n",
    "                pid = tok[:idx].strip()\n",
    "                prob = tok[idx+1:-1].strip()\n",
    "                try: prob = float(prob)\n",
    "                except: prob = None\n",
    "                preds.append((pid, prob))\n",
    "        predicted_targets[cid] = preds\n",
    "\n",
    "# ID 映射\n",
    "pred_map = {}\n",
    "with open(predicted_target_mapping_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        if len(row) < 2: continue\n",
    "        pred_map[row[0].strip()] = row[1].strip()\n",
    "\n",
    "# 组合成分→靶点\n",
    "ingredient_data = []\n",
    "with open(ingredient_output, \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for herbname, _, cid in reader:\n",
    "        ingredient_data.append((herbname, cid))\n",
    "\n",
    "output_target_rows = []\n",
    "for herbname, cid in ingredient_data:\n",
    "    if cid in known_targets:\n",
    "        for prot in known_targets[cid]:\n",
    "            output_target_rows.append([herbname, cid, prot, 1])\n",
    "    if cid in predicted_targets:\n",
    "        for pid, prob in predicted_targets[cid]:\n",
    "            pname = pred_map.get(pid, pid)\n",
    "            output_target_rows.append([herbname, cid, pname, prob])\n",
    "\n",
    "with open(target_output, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"herbname\", \"PubChem_CID\", \"protein\", \"probability\"])\n",
    "    writer.writerows(output_target_rows)\n",
    "print(f\"靶点文件已生成：{target_output}\")\n",
    "\n",
    "####################################\n",
    "# 第 5 部分：批量获取 CanonicalSMILES 并写回\n",
    "####################################\n",
    "# 读取刚才的成分文件\n",
    "rows = []\n",
    "unique_cids = set()\n",
    "with open(ingredient_output, \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for r in reader:\n",
    "        rows.append(r)\n",
    "        cid = r.get(\"PubChem_CID\",\"\").strip()\n",
    "        if cid:\n",
    "            unique_cids.add(cid)\n",
    "\n",
    "if not rows:\n",
    "    print(\"■ 未检测到任何成分行，跳过 SMILES 获取 ■\")\n",
    "else:\n",
    "    # 分批调用 PubChem API\n",
    "    cid_list = list(unique_cids)\n",
    "    batch_size = 100\n",
    "    cid2smiles = {}\n",
    "    for i in range(0, len(cid_list), batch_size):\n",
    "        batch = cid_list[i:i+batch_size]\n",
    "        url = (\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/\"\n",
    "               f\"compound/cid/{','.join(batch)}/property/CanonicalSMILES/JSON\")\n",
    "        try:\n",
    "            resp = requests.get(url, timeout=10)\n",
    "            data = resp.json()\n",
    "            for prop in data.get(\"PropertyTable\",{}).get(\"Properties\",[]):\n",
    "                c = str(prop.get(\"CID\",\"\")).strip()\n",
    "                s = prop.get(\"CanonicalSMILES\",\"\").strip()\n",
    "                cid2smiles[c] = s\n",
    "        except Exception as e:\n",
    "            print(f\"SMILES 批 {i}-{i+batch_size} 请求异常：{e}\")\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    # 更新并写回\n",
    "    for r in rows:\n",
    "        cid = r.get(\"PubChem_CID\",\"\").strip()\n",
    "        r[\"smiles\"] = cid2smiles.get(cid, \"\")\n",
    "    fieldnames = list(rows[0].keys())\n",
    "    with open(ingredient_output, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "    print(f\"已更新 smiles 字段，文件：{ingredient_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T08:43:39.665430Z",
     "iopub.status.busy": "2025-05-15T08:43:39.665014Z",
     "iopub.status.idle": "2025-05-15T08:43:39.872167Z",
     "shell.execute_reply": "2025-05-15T08:43:39.871704Z",
     "shell.execute_reply.started": "2025-05-15T08:43:39.665392Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成，结果已保存到：/slurm/home/yrd/liaolab/tanshuoyan/TCM-opt-Tan/PD/herb/TGD-herb/target/TGD-target-from-BATMAN-processed-ignore-compound.csv\n"
     ]
    }
   ],
   "source": [
    "##step2\n",
    "####对方剂的靶点进行加权统计获得药材靶点权重，method 1\n",
    "####这里忽略成分和相互作用概率,得到的第二列protein_weight均≤1\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 路径设置\n",
    "base_dir   = \"/slurm/home/yrd/liaolab/tanshuoyan/TCM-opt-Tan/PD/herb/TGD-herb\"\n",
    "txt_file   = os.path.join(base_dir, \"TGD.txt\")\n",
    "target_csv = os.path.join(base_dir, \"TGD-target-fromBATMAN.csv\")\n",
    "out_dir    = os.path.join(base_dir, \"target\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_csv    = os.path.join(out_dir, \"TGD-target-from-BATMAN-processed-ignore-compound.csv\")\n",
    "\n",
    "# 1. 读取配方中药材用量，计算权重\n",
    "#    DBYW.txt 无表头，两列：药材,用量\n",
    "df_w = pd.read_csv(\n",
    "    txt_file,\n",
    "    sep=\",\",            # 按逗号切分\n",
    "    header=None,\n",
    "    names=[\"herbname\", \"amount\"],\n",
    "    dtype={\"herbname\": str, \"amount\": float},\n",
    "    engine=\"python\"\n",
    ")\n",
    "total_amount = df_w[\"amount\"].sum()\n",
    "df_w[\"weight\"] = df_w[\"amount\"] / total_amount\n",
    "\n",
    "# 2. 读取 BATMAN 靶点文件\n",
    "#    四列：herbname, PubChem_CID, protein, probability\n",
    "df_t = pd.read_csv(target_csv, dtype=str)\n",
    "\n",
    "# 3. 合并药材权重到靶点表（按 herbname）\n",
    "df = pd.merge(\n",
    "    df_t,\n",
    "    df_w[[\"herbname\", \"weight\"]],\n",
    "    on=\"herbname\",\n",
    "    how=\"left\"\n",
    ")\n",
    "# 如果有个别 herbname 未匹配上，用 0 权重替代\n",
    "df[\"weight\"] = df[\"weight\"].fillna(0.0)\n",
    "\n",
    "# 4. 对同一 herb–protein 对只计一次权重（避免重复行多次累加）\n",
    "df_unique = df[[\"herbname\", \"protein\", \"weight\"]].drop_duplicates(subset=[\"herbname\", \"protein\"])\n",
    "\n",
    "# 5. 按 protein 聚合：各 herb weight 直接相加\n",
    "df_out = (\n",
    "    df_unique\n",
    "    .groupby(\"protein\", as_index=False)[\"weight\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"weight\": \"protein_weight\"})\n",
    ")\n",
    "\n",
    "# 6. 保存结果\n",
    "df_out.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"处理完成，结果已保存到：{out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T08:43:41.368290Z",
     "iopub.status.busy": "2025-05-15T08:43:41.367007Z",
     "iopub.status.idle": "2025-05-15T08:43:41.535782Z",
     "shell.execute_reply": "2025-05-15T08:43:41.535338Z",
     "shell.execute_reply.started": "2025-05-15T08:43:41.368268Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成，结果已保存到：/slurm/home/yrd/liaolab/tanshuoyan/TCM-opt-Tan/PD/herb/TGD-herb/target/TGD-target-from-BATMAN-processed-consider-compound.csv\n"
     ]
    }
   ],
   "source": [
    "##step2\n",
    "####对方剂的靶点进行加权统计获得药材靶点权重\n",
    "####这里考虑成分，但是忽略相互作用概率，method 2\n",
    "# 路径设置\n",
    "base_dir   = \"/slurm/home/yrd/liaolab/tanshuoyan/TCM-opt-Tan/PD/herb/TGD-herb\"\n",
    "txt_file   = os.path.join(base_dir, \"TGD.txt\")\n",
    "target_csv = os.path.join(base_dir, \"TGD-target-fromBATMAN.csv\")\n",
    "out_dir    = os.path.join(base_dir, \"target\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_csv    = os.path.join(out_dir, \"TGD-target-from-BATMAN-processed-consider-compound.csv\")\n",
    "\n",
    "# 1. 读取配方中药材用量，计算权重\n",
    "df_w = pd.read_csv(\n",
    "    txt_file,\n",
    "    sep=\",\",            # 按逗号切分\n",
    "    header=None,\n",
    "    names=[\"herbname\", \"amount\"],\n",
    "    dtype={\"herbname\": str, \"amount\": float},\n",
    "    engine=\"python\"\n",
    ")\n",
    "total_amount = df_w[\"amount\"].sum()\n",
    "df_w[\"weight\"] = df_w[\"amount\"] / total_amount\n",
    "\n",
    "# 2. 读取 BATMAN 靶点文件\n",
    "#    四列：herbname, PubChem_CID, protein, probability\n",
    "df_t = pd.read_csv(target_csv, dtype=str)\n",
    "\n",
    "# 3. 合并药材权重到靶点表（按 herbname）\n",
    "df = pd.merge(\n",
    "    df_t,\n",
    "    df_w[[\"herbname\", \"weight\"]],\n",
    "    on=\"herbname\",\n",
    "    how=\"left\"\n",
    ")\n",
    "df[\"weight\"] = df[\"weight\"].fillna(0.0)\n",
    "\n",
    "# 4. 考虑成分层面：每个 herb–compound–protein 一次计重\n",
    "df_unique = df.drop_duplicates(subset=[\"herbname\", \"PubChem_CID\", \"protein\"])\n",
    "\n",
    "# 5. 按 protein 聚合：对所有命中该 protein 的 herb–compound 权重求和\n",
    "df_out = (\n",
    "    df_unique\n",
    "    .groupby(\"protein\", as_index=False)[\"weight\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"weight\": \"protein_weight\"})\n",
    ")\n",
    "\n",
    "# 6. 保存结果\n",
    "df_out.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"处理完成，结果已保存到：{out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T08:43:44.981311Z",
     "iopub.status.busy": "2025-05-15T08:43:44.980523Z",
     "iopub.status.idle": "2025-05-15T08:43:45.278855Z",
     "shell.execute_reply": "2025-05-15T08:43:45.278414Z",
     "shell.execute_reply.started": "2025-05-15T08:43:44.981271Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成，结果已保存到：/slurm/home/yrd/liaolab/tanshuoyan/TCM-opt-Tan/PD/herb/TGD-herb/target/TGD-target-from-BATMAN-processed-consider-compound-probability.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40236/2369624672.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique[\"contribution\"] = df_unique[\"weight\"] * df_unique[\"probability\"]\n"
     ]
    }
   ],
   "source": [
    "##step2\n",
    "####对方剂的靶点进行加权统计获得药材靶点权重\n",
    "####这里考虑成分并且也考虑了相互作用概率，method 3\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 路径设置\n",
    "base_dir   = \"/slurm/home/yrd/liaolab/tanshuoyan/TCM-opt-Tan/PD/herb/TGD-herb\"\n",
    "txt_file   = os.path.join(base_dir, \"TGD.txt\")\n",
    "target_csv = os.path.join(base_dir, \"TGD-target-fromBATMAN.csv\")\n",
    "out_dir    = os.path.join(base_dir, \"target\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_csv    = os.path.join(out_dir, \"TGD-target-from-BATMAN-processed-consider-compound-probability.csv\")\n",
    "\n",
    "# 1. 读取配方中药材用量，计算 herb 权重\n",
    "df_w = pd.read_csv(\n",
    "    txt_file,\n",
    "    sep=\",\",\n",
    "    header=None,\n",
    "    names=[\"herbname\", \"amount\"],\n",
    "    dtype={\"herbname\": str, \"amount\": float},\n",
    "    engine=\"python\"\n",
    ")\n",
    "total_amount = df_w[\"amount\"].sum()\n",
    "df_w[\"weight\"] = df_w[\"amount\"] / total_amount\n",
    "\n",
    "# 2. 读取 BATMAN 靶点文件\n",
    "#    列：herbname, PubChem_CID, protein, probability\n",
    "df_t = pd.read_csv(target_csv, dtype=str)\n",
    "\n",
    "# 3. 转成 numeric，缺失或非数字设 0\n",
    "df_t[\"probability\"] = pd.to_numeric(df_t[\"probability\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "# 4. 合并 herb 权重\n",
    "df = pd.merge(\n",
    "    df_t,\n",
    "    df_w[[\"herbname\", \"weight\"]],\n",
    "    on=\"herbname\",\n",
    "    how=\"left\"\n",
    ")\n",
    "df[\"weight\"] = df[\"weight\"].fillna(0.0)\n",
    "\n",
    "# 5. 去重到 herb–compound–protein 级别，保留对应的 probability\n",
    "df_unique = df.drop_duplicates(subset=[\"herbname\", \"PubChem_CID\", \"protein\"])\n",
    "\n",
    "# 6. 计算每条记录对 protein 的贡献： herb_weight * probability\n",
    "df_unique[\"contribution\"] = df_unique[\"weight\"] * df_unique[\"probability\"]\n",
    "\n",
    "# 7. 按 protein 聚合贡献值之和\n",
    "df_out = (\n",
    "    df_unique\n",
    "    .groupby(\"protein\", as_index=False)[\"contribution\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"contribution\": \"protein_weight\"})\n",
    ")\n",
    "\n",
    "# 8. 保存结果\n",
    "df_out.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"处理完成，结果已保存到：{out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T09:06:09.483122Z",
     "iopub.status.busy": "2025-05-15T09:06:09.482559Z",
     "iopub.status.idle": "2025-05-15T09:06:09.631604Z",
     "shell.execute_reply": "2025-05-15T09:06:09.630608Z",
     "shell.execute_reply.started": "2025-05-15T09:06:09.483083Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存标准化结果到：/slurm/home/yrd/liaolab/tanshuoyan/TCM-opt-Tan/PD/herb/TGD-herb/target/TGD-target-from-BATMAN-processed-consider-compound-standardization.csv\n",
      "已保存标准化结果到：/slurm/home/yrd/liaolab/tanshuoyan/TCM-opt-Tan/PD/herb/TGD-herb/target/TGD-target-from-BATMAN-processed-consider-compound-probability-standardization.csv\n"
     ]
    }
   ],
   "source": [
    "##step2：\n",
    "##对蛋白权重进行标准化处理，标准化方法使用最大值归一化（Max–Scaling）方法，并另存为标准化后的权重文件\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 目标目录\n",
    "target_dir = \"/slurm/home/yrd/liaolab/tanshuoyan/TCM-opt-Tan/PD/herb/TGD-herb/target\"\n",
    "\n",
    "# 要处理的文件列表\n",
    "filenames = [\n",
    "    \"TGD-target-from-BATMAN-processed-consider-compound.csv\",\n",
    "    \"TGD-target-from-BATMAN-processed-consider-compound-probability.csv\"\n",
    "]\n",
    "\n",
    "for fname in filenames:\n",
    "    # 构造完整路径并读取\n",
    "    path = os.path.join(target_dir, fname)\n",
    "    df = pd.read_csv(path, dtype=str)\n",
    "    \n",
    "    # 确定权重列（假设是第二列）\n",
    "    weight_col = df.columns[1]\n",
    "    df[weight_col] = df[weight_col].astype(float)\n",
    "    \n",
    "    # 最大值归一化作为药材靶点的标准化权重\n",
    "    max_w = df[weight_col].max()\n",
    "    df_out = pd.DataFrame({\n",
    "        \"protein\": df[\"protein\"],\n",
    "        \"protein_weight\": df[weight_col] / max_w\n",
    "    })\n",
    "    \n",
    "    # 构造输出文件名，并保存\n",
    "    base, _ = os.path.splitext(fname)\n",
    "    out_fname = f\"{base}-standardization.csv\"\n",
    "    out_path = os.path.join(target_dir, out_fname)\n",
    "    df_out.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"已保存标准化结果到：{out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
